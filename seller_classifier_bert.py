# -*- coding: utf-8 -*-
"""BERT_seller_classifier.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1qvg60JNxMgJjgmJtAp9PeUX9PluxpvNJ

## Text classifier for selter type (private, dealer) based on description

Install required packages
"""

pip install sentencepiece==0.1.91

pip install ktrain

"""Imports"""

import ktrain
from ktrain import text
import os
import requests
import pandas as pd
from sklearn.model_selection import StratifiedShuffleSplit

"""Environment Setup"""

# Commented out IPython magic to ensure Python compatibility.
# Python first checks if the module is already cached in the sys.module 
# dictionary and only loads if not there
# https://switowski.com/blog/ipython-autoreload

# This code will reload changed modules every time before executing code 
# %reload_ext autoreload
# %autoreload 2   #option 2 - auto reload all the modules

# %matplotlib inline

# set the environment variable CUDA_DEVICE_ORDER to "PCI_BUS_ID" â€“ this will 
# cause the numbering to match NVIDIA's.
os.environ["CUDA_DEVICE_ORDER"]="PCI_BUS_ID";

# 0 is the fastest GPU for NVIDIA
os.environ["CUDA_VISIBLE_DEVICES"]="0";

"""Read in training data from google drive share"""

DATA_URL = "https://drive.google.com/uc?export=download&confirm=7B-T&id=1-U8Fld1M9j0Q-JUVxtAd_OjEvXr5BBvN"
df = pd.read_csv(DATA_URL)
df.head()

"""Split data into train and test - stratify on isDealer"""

X, y = df['description'], df['isDealer']
sss = StratifiedShuffleSplit(n_splits=1, test_size=0.2, random_state=0)
for train_idx, test_idx in sss.split(df, df['isDealer']):
  X_train, y_train = X.loc[train_idx].to_list(), y.loc[train_idx].to_list()
  X_test, y_test = X.loc[test_idx].to_list(), y.loc[test_idx].to_list()

"""Validate the proportions for isDealer are approximately the same """

pd.Series(y_train).value_counts(normalize=True)

pd.Series(y_test).value_counts(normalize=True)

len(X_train), len(y_train), len(X_test),  len(y_test)

class_names = ['private', 'dealer']

"""Build Distilbert Learner"""

model_name = 'bert-base-uncased'

trans = text.Transformer(model_name = model_name, maxlen = 512, class_names = class_names)

train_data = trans.preprocess_train(X_train, y_train)
test_data = trans.preprocess_test(X_test, y_test)

model = trans.get_classifier()

learner = ktrain.get_learner(model, train_data, test_data, batch_size=10)

learner.lr_find(max_epochs=10, show_plot=True)

learner.fit_onecycle(7.75e-06 , 20)

learner.validate(class_names=class_names)

"""# Make predictions on the entire set of descriptions

Read in all descriptions from google drive share - we will be predicting on these in the end
"""

UD_URL = "https://drive.google.com/u/0/uc?export=download&confirm=fTAa&id=1w2pUZAQ80cp-tFNPYzBRgoR7aBNOU62N"
ud = pd.read_csv(UD_URL, compression='zip')

# get the indicies of the null values
null_ind = ud[ud.description.isnull()].index
# add some placeholder text in the null values temporarily
ud[ud.description.isnull()] = 'this is a null value'
# convert to list for BERT input
ud = ud['description'].to_list()

predictor = ktrain.get_predictor(learner.model, preproc=trans)

y_hat = predictor.predict(ud)

out = pd.DataFrame({'dealer': y_hat})

# change indicies of null values to missing
out.loc[null_ind, :] = None

out.to_csv('seller.csv',index = False)
from google.colab import files
files.download("seller.csv")